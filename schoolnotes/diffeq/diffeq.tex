\documentclass[nobib,notoc]{tufte-handout}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{mathrsfs}
\usepackage{IEEEtrantools}
\usepackage{enumitem}

\renewcommand{\IEEEQED}{\IEEEQEDopen}

\begin{document}

\theoremstyle{definition}\newtheorem{defi}{Definition}[section]
\theoremstyle{definition}\newtheorem{axiom}{Axiom}[section]
\theoremstyle{definition}\newtheorem{thm}{Theorem}[section]
\theoremstyle{definition}\newtheorem{cor}{Corollary}[section]
\theoremstyle{definition}\newtheorem{lem}{Lemma}[section]
\theoremstyle{remark}\newtheorem*{notat}{Notation}
\theoremstyle{remark}\newtheorem*{rema}{Remark}
\theoremstyle{definition}\newtheorem{problem}{Problem}
%\renewcommand{\theproblem}{\arabic{problem}}
\newenvironment{prob}[1]{\protect\setcounter{problem}{#1}\addtocounter{problem}{-1}\begin{problem}}{\end{problem}}

\title{Differential Equations}
\author{Samuel Lindskog}
\maketitle

\setcounter{section}{1}

\section{First-Order Differential Equations}
\subsection{Helpful terms and theorems}
\begin{defi}[Order]
	The order of a differential equation is the order of the highest dericatice appearing in the equation.
\end{defi}
\begin{defi}[Normal form]
	The normal form of a first-order equation is a function \(f\) which relates a function \(x=x(t)\) with its first derivative.
	\begin{equation*}
		x'=f(t,x).
	\end{equation*}
	A function \(x=x(t)\) is a solution of this equation on the time interval \(I:a<t<b\) if it is differentiabe on \(I\) and, when substituted into the equation, it satisfies the equation identically for every \(t\in I\), i.e.
	\begin{equation*}
		x'(t)=f(t,x(t)),\text{ for every }t\in I.
	\end{equation*}
	In other words to check if a function is a solution, substitute the function in question into the differential equation and check that it reduces to an identity.
\end{defi}
\begin{defi}[Initial value problem]
	Subjecting a differential equation involving \(x(t)\) and its derivatives to a condition \(x(t_0)=x_0\) is called an initial value problem. The interval of existance of an IVP is the largest time interval where the solution is valid.\footnote{A solution to an IVP is called a particular solution.}
\end{defi}
\begin{defi}[General solution]
	The infinite set of solutions of a first-order equation is called the general solution of the equation.
\end{defi}
\begin{defi}[Nullclines and isoclines]
	The sets of points \((t,x)\) where the slope field is zero are called nullclines\footnote{These constant solutions \(f(t,x)=k\) for some constant \(k\) are called equilibrium solutions.}, i.e. where
	\begin{equation*}
		x'=f(t,x)=0.
	\end{equation*}
	The set of points \(t,x\) where \(f(t,x)=k\) for some constant \(k\) are called isoclines. When we say set of points, we mean the non-empty pre image \(\{k\}\).
\end{defi}
\begin{thm}[Fundamental theorem of calculus]
	\,
	\begin{equation*}
		\frac{d}{dt}\int_{a}^{t}g(s)ds=g(t)
	\end{equation*}
\end{thm}
\begin{thm}[Existence and uniqueness]
	Assume the function \(f(t,x)\) and its partial derivative \(f_x(t,x)\) are continuous in a rectangle \(a<t<b, c<x<d\). Then, for any value \(t_0\) in \(a<t<b\) and \(x_0\) in \(c<x<d\), the initial value problem
	\begin{IEEEeqnarray*}{c}
		x'=f(t,x)\\
		x(t_0)=x_0
	\end{IEEEeqnarray*}
	has a unique solution valid on some open interval \(a<\alpha<t<\beta<b\) containing \(t_0\).
\end{thm}
\begin{defi}[Integral curve]
	After simplifying a differential equation so that it is in terms of \(x\) and \(t\), we obtain a one-parameter family of curves \(\phi(t,x)=C\) in the \(t,x\) plane, consisting of the pre-images of \(\phi(t,x)\) under \{C\}. These so-called integral curves define implicit solutions of the equation. Explicit solutions are the curves for particular values of \(C\).
\end{defi}
\subsection{Seperable equations}
\begin{defi}[Seperable equation]
	A differential equation of the form
	\begin{equation*}
		\frac{dx}{dt}=f(x)g(t)
	\end{equation*}
	is called a seperable equation. We can obtain \(x\) through the following procedure:
	\begin{IEEEeqnarray*}{rCl}
		\frac{dx}{dt}&=&f(x)g(t)\\
		\int\frac{1}{f(x)}\frac{dx}{dt}dt&=&\int g(t)dt\\
		\int\frac{1}{f(x)}dx&=&\int g(t)dt+C
	\end{IEEEeqnarray*}
	The final form of the seperable equation is made possible by the chain rule, and a helpful step forward towards finding the solution is
	\begin{equation*}
		e^{\int g(t)dt}=f(x)+c.
	\end{equation*}
	Equations where \(x'\) is related to a non-identity function of \(x\) can not utilize the quick natural log method in equation \ref{nlogmethod}.
\end{defi}
\begin{defi}[Homogeneous equation]
	A first-order linear differential equation is called homogeneous\footnote{A homogenous equation is seperable.} if it is of the form
	\begin{equation*}
		x'+p(t)x=0.
	\end{equation*}
The solution is
\begin{equation}
	x=Ce^{-\int p(t)dt}.\label{nlogmethod}
\end{equation}
\end{defi}
\begin{defi}[Autonomous equation]
	An autonomous differential equation is a differential equation with no explicit time dependence, i.e.
	\begin{equation*}
		\frac{dx}{dt}=f(x).
	\end{equation*}
	As described above, constant solutions to an autonomous equation are called steady-state or equilibrium solutions.
\end{defi}
\begin{defi}[Stable and unstable equilibrium]
	For stable equilibrium solutions, solutions with values of \(x\) close to the phase-line converge to the phase line. For unstable equilibrium solutions are not stable.\footnote{If solutions near the phase line converge or diverge depending on how they approach, the solution is semi-stable. If all perturbations converge to the phase line, the solution is globally stable.} The roots of \(f(x)=0\) are the equilibrium solutions.
\end{defi}
\begin{thm}
	Let \(x^*\) be an isolated critical point, or equilibrium, for the autonomous equation
	\begin{equation*}
		\frac{dx}{dt}=f(x).
	\end{equation*}
	If \(f'(x^*)<0\), then \(x^*\) is stable. If \(f'(x^*)>0\), then \(x^*\) is unstable. If \(f'(x^*)=0\) then higher derivatives must be analysed to find information about stability.
\end{thm}
\begin{rema}
	As a recap, both homogenous and autonomous equations are seperable, but seperable equations are not necessarily either of these. Their forms are
	\begin{enumerate}
		\item \(x'+f(x)g(t)=0\)\qquad (seperable)
		\item \(x'+p(t)x=0\)\qquad (homogenous)
		\item \(x'+f(x)=0\)\qquad (autonomous)
	\end{enumerate}
	It should also be noted that seperable equations are not necessarily linear.
\end{rema}
\begin{rema}
	A technique for solving seperable IVP's is to unilize definite integrals during the integration step. This involves taking the definite integral of \(f(x)\) starting at \(x_0\), and the definite integral of \(g(t)\) starting at \(t_0\), i.e.
	\begin{equation*}
		\int_{x_0}^x\frac{1}{f(y)}dy=\int_{t_0}^t g(s)ds.
	\end{equation*}
	This works by adjusting the constant of integration of both sides so that they are equal under the initial condition \(x(t_0)=x_0\).
\end{rema}
\subsection{Non-seperable equations}
\begin{defi}[Linear equation]
	A differential equation of the form
	\begin{equation}
		\label{d1normal}
		x'+p(t)x=q(t)
	\end{equation}
	is called a first-order linear equation\footnote{This is also called the normal form of a first-order linear equation.}. If a first-order equation can not be put into this form, the equation is called nonlinear.
\end{defi}
\begin{defi}[Forcing term]
	The term \(q(t)\) in equation \ref{d1normal} is called the forcing term, or source term.
\end{defi}
\begin{defi}[Integrating factor]
	A function \(\mu(t)\) exists such that
	\begin{equation*}
		\mu(t)(x'+p(t)x)=(\mu(t)x)'.
	\end{equation*}
	The function \(\mu(t)\) is called an integrating factor and is given by
	\begin{equation*}
		\mu(t)=e^{\int p(t)dt}
	\end{equation*}
	This can be used to solve linear equations by multiplying both sides by the integrating factor.
\end{defi}
\begin{thm}[Structure]
	Consider the normal form of a first order linear equation
	\begin{equation*}
		x'+p(t)x=q(t).
	\end{equation*}
	The general solution \(x(t)\) is the sum of the general solution to the homogeneous equation plus any solution to the nonhomogeneous equation. i.e.
	\begin{equation*}
		x(t)=x_h(t)+x_p(t),
	\end{equation*}
	where
	\begin{equation*}
		x_h(t)=Ce^{-P(t)},\quad x_p(t)=e^{-P(t)}\int q(t)e^{P(t)}dt.
	\end{equation*}
	Therefore, the solution consists of two parts, the transient (homogenous) solution \(x_h(t)\) and the steady-state (particular) solution \(x_p(t)\).
\end{thm}
\begin{defi}[Bifurcation]
	Bifurcation is said to occur when there is a significant change in the character of the equilibrium solutions, as the bifurcation parameter \(h\) changes. Such a parameter could be the harvesting rate of a fish population in an environment with a set carrying capacity. Bifurcation diagrams plot the equilibium solutions \(x^{*}\) on the \(y\)-axis vs the bifurcation parameter \(h\) on the \(x\)-axis.
\end{defi}
\section{Second-order linear equations}
\begin{defi}[Linear equation]
	The normal form of a second-order linear differential equation is
	\begin{equation*}
		ax''+bx'+cx=f(t).
	\end{equation*}
	In some equations \(b\) is the damping coefficient, and \(c\) the spring constant.
\end{defi}
\subsection{Homogeneous equations}
\begin{defi}[Homogeneous linear equation with constant coefficients]
	\,
	\begin{equation}
		\label{homogen2}
		ax''+bx'+cx=0.
	\end{equation}
\end{defi}
\begin{defi}[Hooke's law]
	Let \(x\) be displacement from equilibrium and \(k\) be the spring constant. Then
	\begin{equation*}
		F_s=-kx
	\end{equation*}
\end{defi}
\begin{defi}[Spring-mass equation]
	The spring-mass equation relates the acceleration of a mass on a spring with the force applied by the spring given by Hooke's law:
	\begin{equation*}
		mx''=-kx.
	\end{equation*}
	For initial conditions \(x(0)=x_0\) and \(x'(0)=0\) we find \(x(t)\) is
	\begin{equation*}
		x(t)=x_0\text{cos}\,\sqrt{k/m}t.
	\end{equation*}
\end{defi}
\begin{defi}[Damped Oscillator]
	If there is friction as the mass moves, the frictional force is a function of the velocity \(x'\) and the damping coefficient \(\gamma\)
	\begin{equation*}
		F_d=-\gamma x'.
	\end{equation*}
	Therefore the equation of motion is
	\begin{equation*}
		mx''=-\gamma x'-kx.
	\end{equation*}
\end{defi}
\begin{rema}
	The damped spring-mass equation has the form\footnote{An equation of this form is called a homogenous linear equation with constant coefficients.}
	\begin{equation*}
		ax''+bx'+cx=0.
	\end{equation*}
	For such an equation, there are always exactly two independent solutions \(x_1(t)\) and \(x_2(t)\), and so the general solution \(\phi(t)\)is of the form
	\begin{equation*}
		\phi(t)=c_1x_1(t)+c_2x_2(t).
	\end{equation*}
\end{rema}
\begin{defi}[Characteristic equation]
	To solve equation \ref{homogen2}, first note that \(x(t)=e^{\lambda t}\) for some constant \(\lambda\). Substituting \(e^{\lambda t}\), we can solve for \(\lambda\) with the characteristic equation\footnote{The roots of this equation are called eigenvalues.}
	\begin{equation*}
		a\lambda^2+b\lambda+c=0.
	\end{equation*}
	The values of \(\lambda\) can be real or complex. If \(b^2-4ac>0\), then there are two real unequal eigenvalues, and hence there are two indpendent solutions, so the general solution is
	\begin{equation*}
		x(t)=c_1e^{\lambda_1 t}+c_2e^{\lambda_2 t}.
	\end{equation*}
	In this case, if \(\lvert\lambda_1\rvert=\lvert\lambda_2\rvert\), then the general solution is
	\begin{equation*}
		x(t)=c_1e^{\alpha t}+c_2e^{-\alpha t}
	\end{equation*}
	Which is exponential. If \(\lvert \lambda_1\rvert=a\), this equation can be written in terms of hyperbolic functions cosh and sinh as
	\begin{equation*}
		x(t)=c_1\text{cosh}\,at+c_2\text{sinh}\,at
	\end{equation*}
	If \(b^2-4ac=0\) then the general solution is
	\begin{equation*}
		x(t)=c_1e^{\lambda t}+c_2te^{\lambda t}.
	\end{equation*}
	If \(b^2-4ac<0\) then the eigenvalues are complex.
\end{defi}
\begin{defi}[Euler's formula]
	\,
	\begin{equation*}
		e^{i\beta t}=\text{cos}\,\beta t+i\text{sin}\,\beta t.
	\end{equation*}
\end{defi}
\begin{thm}
	\label{thm:csolutions}
If \(x(t)=g(t)+ih(t)\) is a complex-valued solution of differential equation \ref{rema:eqn}, then its real and imaginary parts \(x_1(t)=g(t)\) and \(x_2(t)=h(t)\) are real-valued solutions.
\end{thm}
\begin{rema}
	As a consequence of theorem \ref{thm:csolutions}, if \(\lambda_1=\alpha+i\beta\), then the general solution to equation \ref{rema:eqn} is
	\begin{equation*}
		x(t)=c_1e^{\alpha t}\text{cos}\,\beta t+c_2e^{\alpha t}\text{sin}\,\beta t.
	\end{equation*}
	If \(\alpha<0\), these solutions represent decaying oscillations, and if \(\alpha>0\) then these solutions represent growing oscillations. If \(\alpha=0\) then the solutions are purely oscillatory with frequency \(\beta\) and period \(2\pi/\beta\).
\end{rema}
\begin{defi}[Phase-amplitude form]
	The general solution
	\begin{equation*}
		x(t)=c_1\text{cos}\,\beta t+c_2\text{sin}\,\beta t
	\end{equation*}
	can be written as
	\begin{equation*}
		A\text{cos}\,(\beta t-\rho).
	\end{equation*}
	The constants \(A\) and \(\rho\) are related to \(c_1\) and \(c_2\) by
	\begin{equation*}
		A=\sqrt{c_1^2+c_2^2},\qquad\rho=\text{arctan}\,\frac{c_2}{c_1}.
	\end{equation*}
	\(A\) is the amplitude and \(\rho\) is the phase. If \(c_1<0\), then we add \(\pi\) to \(\rho\).
\end{defi}
\begin{defi}[Damping]
	Suppose the motion of a mass-spring system is governed by the equation
	\begin{equation*}
		mx''+\gamma x'+kx=0,\qquad m,\gamma,k>0.
	\end{equation*}
	If \(\gamma^2-4mk>0\), the eigenvalues are real, distinct, negative, and the sytem is overdamped. If \(\gamma^2=4mk\), the eigenvalues are real, equal, and negative, and the system is critically damped. If \(\gamma^2-4mk<0\), the eigenvalues are complex, have negative real part, and the system is underdamped.\footnote{If the system is not underdamped, we say it decays without oscillations. If it is underdamped, we say it oscillates with decay.}
\end{defi}
\begin{defi}[Envelope]
	An envelope of a planar family of curves is a curve that is tangent to each member of the family at some point
\end{defi}
\subsection{Nonhomogeneous equations}
\begin{defi}[Nonhomogeneous equation]
	A nonhomogeneous equation is of the form
	\begin{equation*}
		\label{nonhomo2}
		ax''+bx'+cx=f(t).
	\end{equation*}
	The term \(f(t)\) is called the forcing term.
\end{defi}
\begin{thm}[Structure theorem]
	The general solution of the nonhomogeneous equation \ref{nonhomo2} is given by the sum of the general solution to the homogeneous equation \ref{homogen2} and any specific solution to the nonhomogeneous equation. In other words
	\begin{equation*}
		x(t)=c_1x_1(t)+c_2x_1(t)+x_p(t).
	\end{equation*}
\end{thm}
\begin{defi}[Undetermined coefficients]
	Guess the form of \(x_p(t)\) from the form of the source term \(f(t)\). Some guesses include
	\bigbreak
	\begin{tabular}{l|l}
		Form of source function \(f(t)\)&Trial form of particular solution \(x_p(t)\)\\
		\hline
		\(\alpha\)&\(A\)\\
		\(\alpha^{\beta t}\)&\(Ae^{\beta t}\)\\
		polynomial of degree \(n\)&\(A_nt^n+A_{n-1}t^{n-1}+\ldots+A_1t+A_0\)\\
		\(\alpha\text{sin}\,\omega t;\;\alpha\text{cos}\,\omega t\)&\(A\text{sin}\,\omega t+B\text{cos}\,\omega t\)\\
		\(\alpha e^{rt}\text{sin}\,\omega t;\;\alpha e^{rt}\text{cos}\,\omega t\)& \(e^{rt}(A\text{sin}\,\omega t+B\text{cos}\,\omega t)\)\\
		\hline
	\end{tabular}
	\bigbreak
	If a term in the initial guess for a particular solution \(x_p\) is not linearly independent from the homogeneous solution, then modify the guess by multiplying by the smallest power of \(t\) that eliminates linear dependence.
\end{defi}
\begin{defi}[Beats]
	A system exhibits the phenomenon of beats when a high frequency is modulated by a low frequency. This occurs when the frequency of the homogeneous equation is different then that of the forcing function. In undamped systems
	\begin{equation*}
		x''+\omega_0 t=Acos(\omega t)
	\end{equation*}
	Beats occur when \(\omega_0^2\neq\omega\). Otherwise resonance occurs.
\end{defi}
\section{Laplace transforms}
\begin{defi}[Laplace transform]
	Let \(x=x(t)\) be a function defined on the interval \(0\leq t\leq\infty\). The Laplace transform of \(x(t)\) is the function \(X(s)\) defined by
	\begin{equation*}
		X(s)=\int_0^\infty x(t)e^{-st}dt,
	\end{equation*}
	Provided the improper integral exists, meaning
	\begin{equation*}
		\lim_{b\rightarrow\infty}\int_{0}^{b}x(t)e^{-st}dt\text{ exists.}
	\end{equation*}
	Often, the Laplace transform is repersented in function notation,
	\begin{equation*}
		\mathcal{L}[x(t)](s)=X(s)\text{ or }\mathcal{L}[x]=X(s).
	\end{equation*}
	In this context, \(t,x\) are called time domain variables, and \(s,X\) are called transform domain variables.
\end{defi}
\begin{thm}
	The Laplace transform is a linear operation.
\end{thm}
\begin{rema}
	There are two conditions that guarantee existence of a Laplace transform for a function. first, we require that \(f(t)\) not grow too fast, i.e. if \(M>0\) and \(r\) are constants then
	\begin{equation*}
		\lvert f(t)\rvert\leq Me^{rt}
	\end{equation*}
	for all \(t>t_0\). Second, we require that \(f(t)\) be piecewise continuous on \(0\leq t<\infty\). This means that on any bounded subinterval of \(0\leq t<\infty\)k we assume that \(f(t)\) has at most a finite number of simple discontinuities, and any point of discontinuity \(f(t)\) has finite left and right limits.
\end{rema}
\begin{defi}[Heaviside function]
	We define the Heaviside function \(H(t)\) by
	\begin{equation*}
		H(t)=\begin{cases}0,&t<0\\1,&t\geq 0\end{cases}
	\end{equation*}
	Its translation by \(a\) units to the right is \(H(t-a)\), or
	\begin{equation*}
		H(t-a)=\begin{cases}0,&t<a\\1,&t\geq a\end{cases}
	\end{equation*}
	A useful identity is
	\begin{equation*}
		H(t-a)=\mathcal{L}^{-1}\big(\frac{1}{s}e^{-as}\big).
	\end{equation*}
\end{defi}
\begin{defi}[Shift property]
	The Laplace transform of a function times an exponential, \(f(t)e^{at}\) is given by
	\begin{equation*}
		\mathcal{L}[f(t)e^{at}]=F(s-a).
	\end{equation*}
\end{defi}
\begin{defi}[Switching property]
	The Laplace transform of a function \(f(t)\) that switches on at \(t=a\) is given by
	\begin{equation*}
		\mathcal{L}^{-1}[e^{-as}F(s)]=H(t-a)f(t-a).
	\end{equation*}
\end{defi}
\section{Linear systems}
\begin{rema}
	Consider the second order autonomous\footnote{not time dependent}, homogenous equation
	\begin{equation}
		\label{lineq1}
		mx''+\gamma x'+kx=0.
	\end{equation}
	This can be re-written in terms of \(x\) and \(y=x'\):
	\begin{equation*}
		my'=-kx-\gamma y\;\Rightarrow\begin{cases}x'=y\\y'=-\frac{k}{m}x-\frac{\gamma}{m}y\end{cases}.
	\end{equation*}
	In fact, we can always reduce a second order linear equation of form \ref{lineq1} be defining \(y=x'\) to the form
	\begin{IEEEeqnarray*}{l}
		x'=ax+by\\
		y'=cx+dy.
	\end{IEEEeqnarray*}
	Systems of linear equations of this form\footnote{\(y\) does not need to be the derivative of \(x\)} can be  can be expressed with matrix multiplication as
	\begin{IEEEeqnarray*}{l}
		\textbf{x}(t)=
		\begin{pmatrix}
			x(t)\\y(t)
		\end{pmatrix},\quad
		\textbf{x'}(t)=
		\begin{pmatrix}
			x'(t)\\y'(t)
		\end{pmatrix}\\
		\textbf{x'}=A\textbf{x},\quad A=
		\begin{pmatrix}
			a&b\\
			c&d
		\end{pmatrix}
	\end{IEEEeqnarray*}
\end{rema}
Due to the nature of this system of differential equation \(x'\) and \(y'\) must be comprised of a combination of their antiderivatives \(x\) and \(y\). The only function which satisfies this requirement is \(\alpha\,\text{exp}(\lambda t)\). Therefore \(\mathbf{x}(t)=(\alpha\,\text{exp}(\lambda t),\beta\,\text{exp}(\lambda t))^{T}\). It follows that \(\mathbf{x}'\) is linearly dependent with \(\mathbf{x}\). Thus solutions for \(\textbf{x}\) are of the form \(v\,\text{exp}(\lambda t)\), where \(v\) is an eigenvector of \(A\) and \(\lambda\) its corresponding eigenvalue.
\begin{rema}
	To find the eigenvalues for a \(2\times 2\) matrix, find the roots of the following equation:
	\begin{equation*}
		\lambda^2-(a+d)\lambda+(ad-cb)=0.
	\end{equation*}
	In other words,
	\begin{equation*}
		\lambda^2-\text{tr}(A)+\text{det}(A)=0.
	\end{equation*}
	Eigenvectors and values determine the nature of possible solution.
\end{rema}
\section{Nonlinear systems}
\begin{rema}
	The phase diagram of a nonlinear system of equations \(x'=f(x,y)\) and \(y'=g(x,y)\) can be approximated by finding its equilibrium points, and then approximating the behavior near these equilibrium points using taylor series of each partial derivative.
	\begin{equation*}
		\begin{pmatrix} (x-x_0)'\\(y-y_0)'\end{pmatrix}=\begin{pmatrix}f'(x_0)&f'(y_0)\\g'(x_0)&g'(y_0)\end{pmatrix}\begin{pmatrix}(x-x_0)\\(y-y_0)\end{pmatrix}
	\end{equation*}
\end{rema}
\begin{defi}[Conservative force]
	Obviously, energy is conserved in any closed physical system. For our purposes, we shall consider the system in question to be a mass \(m\) with position \(x\), velocity \(x'\). If a force \(F=F(x)\) is applied to the mass, the potential energy \(V\) of the system can be expressed as a function of the amount of force applied over a distance, V(x). Because potential energy is usually a function of the distance over which a force is applied, if \(F=F(x,x')\), this is typically interpreted\footnote{Alternatively, \(F(x,x')\) could just be a more complicated forcing function.} as a second force on the object which increases/decreases the kinetic energy of the mass. Therefore the force is not conservative. Mathematically, such a second force could be the friction on the mass as it moves, or negative friction. The relationship between newtons second law, and the total energy of a system with a conservative force is derived below:
	\begin{IEEEeqnarray*}{l}
		F(x)=mx''\\
		x'=y,\quad y'=\frac{1}{m}F(x)\\
		F(x)=my'\\
		F(x)\cdot y=my'\cdot y\\
		F(x)dx=mydy\\
		\int F(x)dx+C=\int mydy=\frac{m}{2}y^2\\
		\frac{m}{2}y^2+V(x)=E
	\end{IEEEeqnarray*}
\end{defi}
\end{document}
