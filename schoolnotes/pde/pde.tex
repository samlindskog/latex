\documentclass{article}

\usepackage{settings}

\geometry{
a4paper,
total={140mm,257mm},
left=35mm,
top=20mm,
}

\title{Partial Differential Equations}
\author{Samuel Lindskog}

\begin{document}
\maketitle
\addtocontents{toc}{\protect\hypertarget{toc}{}}
\tableofcontents
\pagenumbering{gobble}
\clearpage
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Heat equation}
\subsection{One-dimensional heat equation}
\begin{definition}[Thermal energy density]
	\(e(x,t)\) represents thermal energy density of a one-dimensional rod with heat energy flowing only longitudinally. Heat energy in a small slice of width \(\Delta x\) is therefore \(e(x,t)A\Delta x\).
\end{definition}
\begin{definition}[Heat flux]
	\(\phi(x,t)\) represents heat flux, and is the amount of thermal energy per unit time flowing to the right per unit surface area.
\end{definition}
\begin{definition}[Conservation of heat energy]
	The conservation of heat energy equation is
	\begin{equation*}
		\diffp{e}{t}=-\diffp{\phi}{x}+Q.
	\end{equation*}
	\(Q\) is heat energy per unit volume generated per unit time.
	\begin{IEEEproof}
		The change in thermal energy with respect to time of a slice in a system with one-dimensional heat flux is given by the equation
		\begin{IEEEeqnarray*}{l}
			\diff{}{t}\int_a^be\,dx=\phi(a)-\phi(b)+\int_a^bQ(x)\,dx\\
			\int_a^b\diffp{e}{t}dx=\int_a^b\bigg(-\diffp{\phi}{x}+Q(x)\bigg)dx\\
			\int_a^b\bigg(\diffp{e}{t}+\diffp{\phi}{x}-Q(x)\bigg)dx=0\\
			\diffp{e}{t}=-\diffp{\phi}{x}+Q(x)
		\end{IEEEeqnarray*}
	\end{IEEEproof}
\end{definition}
\begin{proposition}
	The relation between thermal energy density and temperature \(u\) is given by the following equation:
	\begin{equation*}
		e(x,t)=c(x)\rho(x)u(x,t).
	\end{equation*}
	\(\rho\) is mass density, and \(c\) is specific heat.
\end{proposition}
\begin{definition}[Fourier's law of heat conduction]
	Heat flux is related to temperature by the following equation, known as Fourier's law of heat conduction:
	\begin{equation*}
		\phi=-K_0\diffp{u}{x}.
	\end{equation*}
	\(K_0\) is the thermal conductivity of the material. Thermal diffusivity \(k\) is given by the equation
	\begin{equation*}
		k=\frac{K_0}{c\rho}.
	\end{equation*}
\end{definition}
\begin{proposition}
	Subbing in Fourier's law of heat conduction, the conservation of heat energy equation becomes
	\begin{equation*}
		c\rho\diffp{u}{t}=K_0\diffp[2]{u}{x}+Q(x).
	\end{equation*}
\end{proposition}
\begin{definition}[Newton's law of cooling]
	Newton's law of cooling states that heat flux at the left boundary is negatively proportional to the difference in temperature between an outside medium and the left side of a one-dimensional system, i.e.
	\begin{equation*}
		-K_0(0)\diffp{u}{x}=-H\big(u(0,t)-u_B(t)\big).
	\end{equation*}
	\(H\) is the heat transfer coefficient, or the convection coefficient. For the right boundary, \(H\) does not have a negative sign.
\end{definition}
\begin{proposition}
	If a boundary is perfecty insulated, heat flux at the boundary is zero.
\end{proposition}
\begin{definition}[Perfect thermal contact]
	Two one-dimensional rods are said to be in perfect thermal contact if temperature is continuous at the boundary and thermal flux is the the same as \(x\) approaches the boundary in both rods.
\end{definition}
\begin{definition}[Equilibrium temperature distribution]
	In solving differential equations involving heat transfer, we are often interested in the equilibrium temprature distribution. This is the temperature distribution a system will reach regardless of the initial temperature distribution. The answer will be a function of \(x\) only.
\end{definition}
\begin{proposition}
	Because of conservation of energy, a perfectly insulated rod with no internal energy source will maintain the total thermal energy given by its initial conditions \(f(x)\) as it approaches equilibrium. Thus the equilibrium temperature distribution must be a constant \(u(x)\) given by the equation
	\begin{equation*}
		u(x)=\int_0^Lf(x)dx.
	\end{equation*}
\end{proposition}
\section{Seperation of variables}
\begin{definition}[Linear operator]
	A linear operator \(L\) satisfies the linearity property if for \(c_1,c_2\in\mathbb{R}\) and \(u_1,u_2\in\{f\,|\,f:\mathbb{R}\rightarrow\mathbb{R}\}\)
	\begin{equation*}
		L(c_1u_1+c_2u_2)=c_1L(u_1)+c_2L(u_2).
	\end{equation*}
\end{definition}
\begin{definition}[Linear equation]
	A linear equation for the unknown function \(u\) with linear operator \(L\) is
	\begin{equation*}
		L(u)=f.
	\end{equation*}
	If \(f=0\), then this is a linear homogeneous equation.
\end{definition}
\begin{proposition}
	It follows from the definition of a linear operator \(L\) that \(L(0)=0\). Therefore \(0\) is a solution to any linear homogeneous equation, also known as the trivial solution.
\end{proposition}
\begin{definition}[Principle of superposition]
	If \(u_1\) and \(u_2\) satisfy a linear homogeneous equation, then any linear combination of these solutions is itself a solution.
\end{definition}
\subsection{Method of seperation of variables}
The method of seperation of variables attempts to determine solutions of linear homogeneous equations using the ansatz
\begin{equation*}
	u(x,t)=\phi(x)G(t).
\end{equation*}
We begin by solving the following BVP:
	\begin{IEEEeqnarray*}{l}
		\text{PDE:}\;\diffp{u}{x}=k\diffp[2]{u}{x},\quad 0<x<L,\;t>0\\
		\text{BC:}\;u(0,t)=0,\;u(L,t)=0\\
		\text{IC:}\;u(x,0)=f(x)
	\end{IEEEeqnarray*}
	This is a linear homogenous differential equation with linear homogenous boundary conditions. Homogeniety of boundary conditions and the properties of linear operators is usually necessary because it allows us to take advantage of the principle of superposition. To begin, sub in product solution \(u(x,t)=\phi(x)G(t)\):
	\begin{IEEEeqnarray*}{l}
		\phi(x)\diff{G}{t}=k\diff[2]{\phi}{x}G(t)\\
		\frac{1}{kG}\diff{G}{t}=\frac{1}{\phi}\diff[2]{\phi}{x}=-\lambda
	\end{IEEEeqnarray*}
	The latter equation is reached as a result of the fact that the derivative operation is a linear operator. A consequence of this is that we can equate a linear combination of \(n\)th derivatives of \(u\) with respect to \(x\) with \(n\)th derivatives of \(u\) with respect to \(t\), while maintaining seperation between independent variables established by the product equation \(u(x,t)=\phi(x)G(t)\). Because \(x\) and \(t\) are independent variables, this equation seperated by its independent parts must be a constant. This yields two ODEs in \(x\) and \(t\):
	\begin{IEEEeqnarray*}{l}
		\diff[2]{\phi}{x}=-\lambda\phi\\
		\diff{G}{t}=-\lambda kG
	\end{IEEEeqnarray*}
	From here, boundary conditions determine solutions to our two ODEs. The homogeniety of the boundary conditions allows us to superimpose all possible solutions of \(u\), which through the nature of our solutions and fourier series means we can represent a wide range of initial conditions. To find all possible solutions for \(u\), we analyse the effect different values of \(\lambda\) have on our ODE solutions. If \(\lambda>0\), solutions for \(\phi(x)\) are of the form
	\begin{IEEEeqnarray*}{l}
		\diff[2]{\phi}{x}=-\lambda\phi,\quad\phi(0)=0,\phi(L)=0\\
		\phi(x)=C_1\cos(\sqrt{\lambda}x)+C_2\sin(\sqrt{\lambda}x),
	\end{IEEEeqnarray*}
and solutions for \(G(t)\) are of the form
	\begin{IEEEeqnarray*}{l}
		\diff{G}{t}=-k\lambda G\\
		G(t)=C_3e^{-k\lambda t}.
	\end{IEEEeqnarray*}
	From here, we see that values of \(\lambda>0\) that meet our boundary conditions are of the form \(\lambda=(n\pi/L)^2,\,n\in\mathbb{N}\setminus\{0\}\), and that \(C_1=0\) for \(\phi\). Therefore if \(\lambda>0\),
	\begin{equation*}
		u(x,t)=B\sin\bigg(\frac{n\pi}{L}x\bigg)e^{-k(n\pi/L)^2t}.
	\end{equation*}
	If \(\lambda=0\) then \(\phi(x)=C_1x+C_2\) and \(G(t)=C_3\), so to meet boundary conditions \(u(x,t)=0\). If \(\lambda<0\) then \(\phi(x)\) and \(G(t)\) are both exponentials multiplied by arbitrary constants, so to meet boundary conditions \(u(x,t)=0\). Therefore for this BVP, nontrivial solutions exist for values of \(\lambda>0\). Such \(\lambda\) are called eigenvalues, and their corresponding solutions are called eigenfunctions.
\subsection{Superposition}
Using the principle of superposition, we see that for solutions \(u_1,\ldots,u_M\), any linear combination of these solutions is itself a solution. Utilizing the theory of Fourier series, we know that
\begin{enumerate}
	\item Most functions can be approximated by a finite linear combination of \(\sin\,n\pi x/L\).
	\item This approximation becomes arbitrarily accurate as \(M\) increases.
	\item As \(M\) approaches infinity, the resulting infinite series converges to \(f(x)\), with some restrictions on \(f(x)\).
\end{enumerate}
Thus for most initial conditions \(f(x)\),
\begin{equation*}
	f(x)=\sum_{n=1}^{\infty}B_n\sin\frac{n\pi x}{L}.
\end{equation*}
Therefore,
\begin{equation}
	\label{forsereq}
	u(x,t)=\sum_{n=1}^{\infty}B_n\sin\,\frac{n\pi x}{L}e^{-k(n\pi/L)^2t}.
\end{equation}
\begin{proposition}[Orthogonality relation]
	\label{orthofsins}
	Functions \(\sin\,\frac{n\pi x}{L}\) and \(\cos\) satisfy the following relation:
	\begin{IEEEeqnarray*}{l}
		\int_0^L\sin\frac{n\pi x}{L}\sin\frac{m\pi x}{L}dx=
		\begin{cases}
			0,&m\neq n\\L/2,&m=n
		\end{cases}\\
		\\
		\int_0^L\cos\frac{n\pi x}{L}\cos\frac{m\pi x}{L}dx=
		\begin{cases}
			0,&n\neq m\\L/2,&n=m\neq0\\L,&n=m=0
		\end{cases}\\
		\int_0^L\cos\frac{n\pi x}{L}\sin\frac{m\pi x}{L}dx=0
	\end{IEEEeqnarray*}
\end{proposition}
\noindent We can use proposition \ref{orthofsins} to calculate the coefficient \(B_m\) in equation \ref{forsereq} by way of the following equation:
\begin{equation*}
	B_m=\frac{2}{L}\int_0^Lf(x)\sin\frac{m\pi x}{L}dx.
\end{equation*}
\section{Fourier series}
\subsection{Introduction}
\begin{definition}[Piecewise smooth]
	A function is piecewise smooth on some interval if the interval can be broken up into pieces such that in each piece the function \(f(x)\) is continuous, and its derivative is also continuous. The function \(f(x)\) may not be continuous, in which case the only discontinuity allowed is a jump discontinuity.
\end{definition}
\begin{definition}[Fourier series]
	The Fourier series of \(f(x)\) over the interval \(-L\leq x\leq L\) is defined to be the infinite series
	\begin{equation*}
		f(x)\sim a_0+\sum_{n=1}^{\infty}a_n\cos\frac{n\pi x}{L}+\sum_{n=1}^{\infty}b_n\frac{n\pi x}{L}.
	\end{equation*}
	Coefficients \(a_0,a_n,b_n\) are determined using the orthogonality integrals
	\begin{IEEEeqnarray*}{rCl}
		a_0&=&\frac{1}{2L}\int_{-L}^{L}f(x)dx\\\\
		a_n&=&\frac{1}{L}\int_{-L}^{L}f(x)\cos\frac{n\pi x}{L}dx\\\\
		b_n&=&\frac{1}{L}\int_{-L}^{L}f(x)\sin\frac{n\pi x}{L}dx
	\end{IEEEeqnarray*}
\end{definition}
\begin{proposition}
	The Fourier series of \(f(x)\) does not exist unless \(a_0\) exists.
\end{proposition}
\begin{theorem}[Fourier's theorem]
	If \(f(x)\) is piecewise smooth on the interval \(-L\leq x\leq L\), then the Fourier series of \(f(x)\) converges in one of two ways:
	\begin{enumerate}
		\item To the periodic extension of \(f(x)\), where the periodic extension is continuous.
		\item To the average of the two limits, usually \(.5[f(x+)+f(x-)]\), where the period extension has a jump discontinuity at \(x\).
	\end{enumerate}
\end{theorem}
\subsection{Fourier cosine and sine series}
\begin{definition}[Odd function]
	An odd function is a function with the property \(f(-x)=-f(x)\).
\end{definition}
\begin{definition}[Even function]
	An even function is a function with the property \(f(-x)=f(x)\).
\end{definition}
\begin{proposition}
	\label{oddevenzero}
	The sine coefficients of the Fourier series of a piecewise smooth even function are zero, and the cosine coefficients of the Fourier series of a piecewise smooth odd function are zero.
\end{proposition}
\begin{proposition}
	\label{evenintegral}
	The integral of an even function over a symmetric interval \(-L\leq x\leq L\) is twice the integral from \(0\leq x\leq L\).
\end{proposition}
\begin{definition}[Fourier sine series]
	The Fourier sine series of a function \(f(x)\) defined on \(0\leq x\leq L\) is an infinite series of odd functions that approximates the odd extension of \(f(x)\)
	\begin{equation*}
		\text{odd extension }f(x)=\begin{cases}
			f(x)&x>0\\
			0&x=0\\
			-f(-x)&x<0\\
		\end{cases}
	\end{equation*}
		on \(-L\leq x\leq L\), i.e.
	\begin{equation*}
		\text{odd extension }f(x)\sim\sum_{n=1}^{\infty}B_n\sin\frac{n\pi x}{L}.
	\end{equation*}
	Because two odd functions multiplied are even, it follows from propositions \ref{oddevenzero} and \ref{evenintegral} that the coefficients \(B_n\) are the same for a Fourier series of the odd extension of \(f(x)\) and the sine series of \(f(x)\) on \(0\leq x\leq L\), i.e.
	\begin{equation*}
		B_n=\frac{1}{L}\int_{-L}^{L}f(x)\sin\frac{n\pi x}{L}dx=\frac{2}{L}\int_{0}^{L}f(x)\sin\frac{n\pi x}{L}dx.
	\end{equation*}
\end{definition}
\begin{corollary}
	The Fourier sine series of \(f(x)\) on \(0\leq x\leq L\) is always \(0\) at \(x=nL,\,n\in\mathbb{Z}\).
\end{corollary}
\begin{definition}[Fourier cosine series]
	The Fourier cosine series of a function \(f(x)\) defined on \(0\leq x\leq L\) is an infinite series of even functions that approximates the even extension of \(f(x)\)
	\begin{equation*}
		\text{even extension }f(x)=\begin{cases}
			f(x)&x\geq0\\
			f(-x)&x<0\\
		\end{cases}
	\end{equation*}
	on \(-L\leq x\leq L\), i.e.
	\begin{equation*}
		\text{even extension }f(x)\sim A_0+\sum_{n=1}^{\infty} A_n\cos\frac{n\pi x}{L}.
	\end{equation*}
	Because two even functions multiplied are even, it follows from propositions \ref{oddevenzero} and \ref{evenintegral} that the coefficients \(A_n\) are the same for a Fourier series of the even extension of \(f(x)\) and the cosine series of \(f(x)\) on \(0\leq x\leq L\), i.e.
	\begin{IEEEeqnarray*}{l}
		A_0=\frac{1}{2L}\int_{-L}^{L}f(x)dx=\frac{1}{L}\int_{0}^{L}f(x)dx,\\
		A_n=\frac{1}{L}\int_{-L}^{L}f(x)\cos\frac{n\pi x}{L}dx=\frac{2}{L}\int_{0}^{L}f(x)\cos\frac{n\pi x}{L}dx.
	\end{IEEEeqnarray*}
\end{definition}
\begin{proposition}
	Any function can be written as
	\begin{equation*}
		f(x)=\frac{1}{2}[f(x)+f(-x)]+\frac{1}{2}[f(x)-f(-x)].
	\end{equation*}
	where the first bracketed term is an even function (\(f_e\)), and the second is an odd function (\(f_o\)).
\end{proposition}
\begin{proposition}
	It follows from proposition \ref{oddevenzero} that the Fourier series of \(f(x)\) equals the Fourier sine series of \(f_o(x)\) plus the Fourier cosine series of \(f_e(x)\).
\end{proposition}
\begin{caution}
	The even/odd extension of \(f(x)\) is not necessarily equal to \(f_e\) or \(f_o\) respectively.
\end{caution}
\begin{proposition}
	For piecewise smooth \(f(x)\), the Fourier series of \(f(x)\) is continuous and converges to \(f(x)\) for \(-L\leq x\leq L\) iff \(f(x)\) is continuous and \(f(-L)=f(L)\).
\end{proposition}
\begin{proposition}
	For piecewise smooth \(f(x)\), the Fourier cosine series of \(f(x)\) is continuous and converges to \(f(x)\) for \(0\leq x\leq L\) iff \(f(x)\) is continuous.
\end{proposition}
\begin{proposition}
	For piecewise smooth \(f(x)\), the Fourier sine series of \(f(x)\) is continuous and converges to \(f(x)\) for \(0\leq x\leq L\) iff \(f(x)\) is continuous and both \(f(0)=0\) and \(f(L)=0\).
\end{proposition}
\subsection{Term-by-term differentiation of Fourier series}
\begin{theorem}
	A Fourier series that is continuous can be differentiated term by term if \(f'(x)\) is piecewise smooth. In other words, if \(f(x)\) is piecewise smooth and continuous, its Fourier series can be differentiated term by term if \(f(-L)=f(L)\).
\end{theorem}
\section{Vibrating strings and membranes}
\subsection{Derivation of a vertically vibrating string}
A perfectly flexible string under tension oscillates. It experiences tension \(T(x,t)\) tangent to the graph of it's displacement with respect to \(x\). Neglecting horizontal motion of points on the string, Newton's second law tells us that for a section of string of length \(\Delta x\),
\begin{IEEEeqnarray*}{rCl}
	\rho_0(x)\Delta x\diffp[2]{u}{t}&=&T(x+\Delta x,t)\sin\big[\theta(x+\Delta x,t)\big]\\
	&&-T(x,t)\sin\big[\theta(x,t)\big]+\rho_0(x)\Delta x Q(x,t),
\end{IEEEeqnarray*}
With \(\rho_0\) the mass density and \(\diffp{u}{x}=\tan(\theta)\). Dividing both sides of this equation by \(\Delta x\) and taking the limit of both sides as \(\Delta x\rightarrow 0\), the equation becomes
\begin{equation*}
	\rho_0\diffp[2]{u}{t}=\diffp{}{x}\bigg[T(x,t)\sin\big[\theta(x,t)\big]\bigg]+\rho_0(x)Q(x,t).
\end{equation*}
Assuming the string's amplitude is small relative to it's length, \(\theta\) is small and the approximation \(\diffp{u}{x}=\tan{\theta}\approx\sin(\theta)\) is relatively accurate. Additionally, if \(\theta\) is small we can assume stretching of the string is minimal and thus tension is constant, i.e. \(T(x,t)=T_0\). Using these additional approximations and assuming \(Q(x,t)=0\), this equations becomes
\begin{equation*}
	\diffp[2]{u}{t}=c^2\diffp{u}{x},
\end{equation*}
With \(c^2=T_0/\rho_0(x)\). This equation is called the one-dimensional wave equation.
\begin{definition}[Normal modes]
	For a string vibrating with fixed ends, solutions can be found via seperation of variables and are a linear combination of product solutions
	\begin{equation*}
		u(x,t)=\sum_{n=1}^{\infty}\sin\frac{n\pi x}{L}\big(A_n\cos\frac{n\pi ct}{L}+B_n\sin\frac{n\pi ct}{L}\big),
	\end{equation*}
	where \(c=\sqrt{T_0/\rho_0}\). Individually, these solutions are called normal modes. The normal mode \(n=1\) is called the first harmonic or fundamental mode. The \(n\)th normal mode is called the \(n\)th harmonic. Normal modes can be written in phase-amplitude form as
	\begin{equation*}
		\sin\frac{n\pi x}{L}\bigg(\sqrt{A_1^2+A_2^2}\sin(\omega t+\theta)\bigg),\quad\theta=\tan^{-1}\frac{A_n}{B_n},\;\omega=\frac{n\pi ct}{L}.
	\end{equation*}
	These waves are standing waves, and their amplitude varies with time with angular frequency \(n\pi c/L\).
\end{definition}
\begin{definition}[Natural frequency]
	The natural frequency of a normal mode is it's angular frequency with respect to time. In the case of a vibrating string with fixed ends this is \(n\pi c/L\).
\end{definition}
\begin{definition}[Node]
	Nodes are non-boundary points on the standing wave which are stationary with time, and occur at the points \(aL/n,\,a\in\mathbb{N}\) with \(0<a\leq n-1\).
\end{definition}
\subsection{Boundary conditions}
For string with constant tension and mass density, the boundary conditions for a free end at \(x=0\) can be derived from variable support boundary conditions. Suppose one end of a string is connected to a mass \(m\) on a spring oriented perpendicularly to the length axis, with the spring's equilibrium position at \(y=0\). It follows from Hooke's law and N2L that
\begin{equation*}
	m\diffp[2]{u}{t}(0,t)=T_0\diffp{u}{x}(0,t)-ku(0,t).
\end{equation*}
If the mass it zero, it then must be the case that
\begin{equation*}
	ku(0,t)=T_0\diffp{u}{x}(0,t).
\end{equation*}
It follows that if \(k=0\), i.e. the end of the string is attached to a frictionless track, that
\begin{equation*}
	T_0\diffp{u}{x}(0,t)=0.
\end{equation*}
This is thus the boundary condition corresponding to a free end at \(x=0\).
\clearpage
\section{Sturm-Liouville eigenvalue problems}
\subsection{Sturm-Liouville differential equations}
\begin{definition}[Sturm-Liouville differential equation]
	A Sturm-Liouville differential equation is an equation of the form
	\begin{equation*}
		\diff{}{x}\bigg(p\diff{\phi}{x}\bigg)+q\phi+\lambda\sigma\phi=0,
	\end{equation*}
	where \(\lambda\) is the eigenvalue, and \(p,q,\sigma\) are functions of \(x\).
\end{definition}
\begin{definition}
	A regular Sturm-Liouville eigenvalue problem consists of a Sturm-Liouville differential equation
	\begin{equation*}
		\diff{}{x}\bigg(p(x)\diff{\phi}{x}\bigg)+q(x)\phi+\lambda\sigma(x)\phi=0,
		\quad a<x<b,
	\end{equation*}
	subject to the boundary conditions
	\begin{IEEEeqnarray*}{rCl}
		\beta_1\phi(a)+\beta_2\diff{\phi}{x}(a)=0\\
		\beta_3\phi(b)+\beta_4\diff{\phi}{x}(b)=0,
	\end{IEEEeqnarray*}
	with \(\beta_i\in\mathbb{R}\). To be called regular, the functions \(p,q,\sigma\) must be real and continuous everywhere including endpoints, and \(p,\sigma>0\) everywhere including endpoints.
\end{definition}
\begin{theorem}[Sturm-Liouville problem theorems]
	For any regular Sturm-Liouville problem, the following theorems are valid:
	\begin{enumerate}
		\item All eigenvalues \(\lambda\) are real.
		\item There exists and infinite number of eigenvalues. There is a smallest eigenvalue (usually denoted \(\lambda_1\)), but not a largest eigenvalue.
		\item Corresponding to each eigenvalue \(\lambda_n\), there is an eigenfunction \(\phi_n(x)\) which is unique to within an arbitrary multiplicative constant. Additionally, \(\phi_n(x)\) has exactly \(n-1\) zeros for \(a<x<b\).
		\item The eigenfuctions \(\phi_n(x)\) form a complete set, meaning that any piecewise smooth function \(f(x)\) can be represented by a generalized Fourier series of the eigenfunctions:
			\begin{equation*}
				f(x)\sim\sum_{n=1}^{\infty}a_n\phi_n(x).
			\end{equation*}
			This infinite series converges to \([f(x+)+f(x-)]/2\) on \(a<x<b\) for some specific \(a_n\).
		\item Eigenfunctions belonging to different eigenvalues are orthogonal relative to the weight function \(\sigma(x)\), i.e.
			\begin{equation*}
				\int_{a}^{b}\phi_n(x)\phi_m(x)\sigma(x)dx=0\quad\lambda_n\neq\lambda_m.
			\end{equation*}
		\item All eigenvalues are related to their respective eigenfunctions by the Rayleigh quotient:
			\begin{equation*}
				\lambda=\frac{-p\phi\,d\phi/dx|_a^b+\int_a^b[p(d\phi/dx)^2-q\phi^2]dx}{\int_{a}^{b}\phi^2\sigma dx},
			\end{equation*}
			where the boundary conditions may somewhat simplify this expression.
	\end{enumerate}
\end{theorem}
\begin{remark}
	The Rayleigh quotient directly proves that \(\lambda\geq 0\) if
	\begin{enumerate}
		\item \(\Eval{-p\phi\diff{\phi}{x}}{a}{b}\geq 0\) and
		\item \(q\leq 0\).
	\end{enumerate}
\end{remark}
\begin{proposition}
	The generalized Fourier coefficients for a given eigenfunction \(\phi_n(x)\) and weight function \(\sigma(x)\) are given by the equation
	\begin{equation*}
		a_n=\frac{\int_a^b f(x)\phi_n(x)\sigma(x)dx}{\int_a^b \phi^2_n(x)\sigma(x)dx}.
	\end{equation*}
\end{proposition}
\begin{theorem}
	The minimum value of the Rayleigh quotient for all continuous functions satisfying the boundary conditions is the lowest eigenvalue.
\end{theorem}
\subsection{Self-adjoint operators}
\begin{definition}[Linear differential operator]
	Let \(L\) stand for the linear differential operator, defined
	\begin{equation*}
		L(y)\equiv\diff{}{x}\bigg[p(x)\diff{y}{x}\bigg]+q(x)y.
	\end{equation*}
\end{definition}
\begin{proposition}
	The Sturm-Liouville differential equation can be written using the operator notation
	\begin{equation*}
		L(\phi)+\lambda\sigma(x)\phi=0.
	\end{equation*}
\end{proposition}
\begin{definition}[Lagrange's indentity] 
	\,
	\begin{equation*}
		uL(v)-vL(u)=\diff{}{x}\bigg[p\bigg(u\diff{v}{x}-v\diff{u}{x}\bigg)\bigg].
	\end{equation*}
\end{definition}
\begin{definition}[Green's formula]
	\,
	\begin{equation*}
		\int_a^b\big[uL(v)-vL(u)\big]dx=\Eval{p\bigg(u\diff{v}{x}-v\diff{u}{x}\bigg)}{a}{b}.
	\end{equation*}
\end{definition}
\begin{theorem}
	If \(u\) and \(v\) are any two functions satisfying the same regular Sturm-Liouville boundary conditions, then
	\begin{equation*}
		\int_a^b[uL(v)-vL(u)]dx=0.
	\end{equation*}
	When this equation is true, we say that the operator \(L\) (with these boundary conditions) is self-adjoint.
\end{theorem}
\subsection{Estimation of eigenvalues}
\begin{theorem}
	\label{contrayleigh}
	The minimum value of the Rayleigh quotient for all continuous functions satisfying the boundary conditions is the lowest eigenvalue.
\end{theorem}
\begin{proposition}[Estimate of upper bound for \(\lambda_1\)]
\noindent Utilizing theorem \ref{contrayleigh}, we can estimate the lowest eigenvalue by choosing a trial function \(u_T\) close to the eigenfunction. Choose a function that satisfies the necessary boundary conditions, and has no zeroes on the corresponding interval.
\end{proposition}
\subsection{Elastic boundary conditions}
\end{document}
